# Agent CVM Docker Compose â€” for Phala Cloud deployment.
# Both orchestrator and inference bridge run in the same CVM.

services:
  lucia-agent:
    build:
      context: ../..
      dockerfile: cvm-images/agent-cvm/Dockerfile
    ports:
      - "8080:8080"
      - "8000:8000"
    environment:
      - PORT=8080
      - INFERENCE_URL=http://localhost:8000
      - INFERENCE_PORT=8000
      - LLM_BACKEND_URL=${LLM_BACKEND_URL:-https://api.redpill.ai/v1}
      - LLM_API_KEY=${LLM_API_KEY:-}
      - MODEL_NAME=${MODEL_NAME:-deepseek/deepseek-chat-v3-0324}
      - VAULT_MASTER_KEY=${VAULT_MASTER_KEY:-}
      - ALLOWED_ORIGINS=${ALLOWED_ORIGINS:-http://localhost:5173}
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:8080/health"]
      interval: 10s
      timeout: 3s
      retries: 3
